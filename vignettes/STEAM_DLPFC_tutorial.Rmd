---
title: "STEAM DLPFC Tutorial"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{STEAM_DLPFC_tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


This vignette outlines the steps of performing a classification analysis on the DLPFC (Dorsolateral Prefrontal Cortex) data by 10x Genomics using the STEAM framework.
Here, cell-type classification is performed by incorporating neighborhood averaging and RandomForest with cross validation.

# Load libraries

```{r setup}
library(STEAM)
library(Seurat)
```

# Load data

DLPFC dataset from Visium by 10X Genomics is provided within the package.
This data is already preprocessed for your use.

```{r message=FALSE, warning=FALSE}
data(DLPFC)
```

# Create the STEAM object

-   `count_exp`: The scaled gene expression matrix extracted earlier (`matrix`).
-   `spatial`: The spatial coordinates of the cells (`coordinates`), providing spatial context for the data.
-   `labels`: The cell type or clusters annotation labels pre-obtained by any clustering methods, which will be served as ground truth or reference for evaluation.
-   `Seurat.obj`: Set to NULL, indicating that no additional Seurat object is being passed for this analysis.

```{r}

# Create a STEAM object using the LoadSTEAM function.
STEAM.obj <- LoadSTEAM(count_exp = DLPFC$matrix, spatial = DLPFC$coordinates, labels = DLPFC$labels, Seurat.obj = NULL)
```

# Run STEAM on the STEAM object using specified parameters

-   `STEAM.obj`: The STEAM object created using the LoadSTEAM function.
-   `train.ratio`: The proportion of data to use for training.
-   `n.size`: Neighborhood size used for averaging spatial data.
-   `seed`: Seed for random number generation to ensure reproducibility of results.
-   `cv.folds`: Number of folds for cross-validation .
-   `cv.repeats`: Number of repetitions for cross-validation.
-   `trainval.ratio`: Ratio for splitting the training set into training and validation subsets.
-   `model`: The machine learning model to use for classification.
    -   `rf` = RandomForest
    -   `svm` = Support Vector Machines,
    -   `xgb` = XGBoost
    -   `multinom` = Multinomial Logistic Regression
-   `n.tree`: Number of trees to use for the Random Forest model.
-   `kernel`: The kernel type for SVM.
-   `train.folder.name`: Name of the folder where training outputs will be stored ('train.out').
-   `allowParallel`: Whether to allow parallel computing for faster execution. Set to FALSE to run sequentially.

```{r}

# Run the STEAM analysis.
STEAM.obj <- RunSTEAM(STEAM.obj,
                      train.ratio = 0.8, 
                      n.size = 5, 
                      seed = 123, 
                      cv.folds = 10, 
                      cv.repeats = 3, 
                      trainval.ratio = 0.8, 
                      model = "rf", 
                      n.tree = 100, 
                      kernel = NULL, 
                      train.folder.name = 'train.out', 
                      allowParallel = TRUE
)

```

```{r}
# Evaluation metrics by generating Kappa, F1-score, Accuracy, etc.
STEAM.obj$test$metrics

```


```{r fig.width=8, fig.height=6, out.width="100%"}
ViewMetrics(STEAM.obj)
```

# View the Feature Importance

feature_importance is calculated depending on the type of model used in STEAM.obj during training.
A brief overview of how feature importance for each model is calculated:

-   `rf`: using varImp() from the `caret` package, the importance scores are extracted and feature importance is calculated as the mean decrease in Gini.
-   `xgb`: this also uses varImp() from the `caret` package and computes importance using Gain, which represents the average improvement in the loss function when a feature is used in a split. 
-   `svm`: the final model is extracted and computes thefeature importance using the absolute magnitude of the weight for each feature. Feature weights are calculated from the dot product of SVM coefficients and the support vector matrix. 
-`multinom`: the coefficient matrix is extracted, containing the feature coefficients for each class. The feature importance is calculated as the sum of absolute coefficient values across all classes. The intercept term is omitted.

```{r, fig.align = "center", fig.width=5, fig.height=6}
# View feature importance
feature_importance(STEAM.obj, top_n = 10, title = "Top Features by Importance")

```

# View the Gene Expression per Layer

The feature_expression function extracts the expression values for the user-specified feature across the different layers and plots how the expression varies across layers.

```{r, fig.align = "center", fig.width=5, fig.height=4}
# Show the gene expression per layer
feature_expression(STEAM.obj, feature_name = "TMSB10", title = "Expression Across Layers")
```

# View the Misclassifications

The plot_misclassified_cells function extracts the spatial coordinates and labels from the STEAM.obj and compares the true labels to the model's predictions in order to identify the misclassified cells.
Misclassifications are shown as black dots on the plot.

```{r, fig.align = "center", fig.width=8, fig.height=7, out.width="70%"}

# Plot misclassified cells
plot_misclassified_cells(STEAM.obj)

```
